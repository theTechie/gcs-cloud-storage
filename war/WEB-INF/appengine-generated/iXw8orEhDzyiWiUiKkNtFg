#include <stdio.h>

// global constants
#define THREADS 4 // 1024 : Maximum number of threads per block

const int N = 1024; // 1024 : Maximum x- or y-dimension of a block based on Compute Capability


__global__ void sum(float* a, float* b, float* c)
{
    int i = threadIdx.x;
    
    if (i < N)
	c[i] = a[i] + b[i];
}

int main(int argc, char **argv)
{
    float *a, *b, *c;
    float *d_a, *d_b, *d_c;
    int SIZE = sizeof(float) * N;

    a = (float*) malloc(SIZE);
    b = (float*) malloc(SIZE);
    c = (float*) malloc(SIZE);
	
    // allocate memory on the device for calculation input and results
    cudaMalloc(&d_a, SIZE);
    cudaMalloc(&d_b, SIZE);
    cudaMalloc(&d_c, SIZE);
	
    for (int i=0; i<N; i++) {
      	a[i] = b[i] = 1;
	c[i] = 0;
    }

    // copy the input values to the gpu-memory
    cudaMemcpy(d_a, a, SIZE, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, SIZE, cudaMemcpyHostToDevice);

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    cudaEventRecord(start, 0);    

    // invokes kernel-method sum on device using device-memory dev_a, dev_b, dev_c
    sum<<<1, N>>>(d_a, d_b, d_c);

    cudaEventRecord(stop, 0);
    cudaEventSynchronize(stop);
    float elapsedTime;
    cudaEventElapsedTime(&elapsedTime, start, stop);

    cudaEventDestroy(start);
    cudaEventDestroy(stop);

    // copy the result values back from the device_memory to the host-memory
    cudaMemcpy(c, d_c, SIZE, cudaMemcpyDeviceToHost);
 

    for(int i=0; i<N; i++)
	printf("c[%d] = %f\n", i, c[i]);
    

    printf("Elapsed Time: %f\n", elapsedTime);	
    
    free(a); free(b); free(c);
    // free memory allocated on device (for input and result values)
    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);

    return 0;
}
